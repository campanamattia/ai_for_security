{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTER 6 CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/dataset/train_sel_hclust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_clustering_comparison(X, n_clusters=6):\n",
    "    # Setup the figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    fig.suptitle('Clustering Comparison: Raw vs Normalized Data', fontsize=16)\n",
    "    \n",
    "    # 1. Prepare data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # 2. Perform clustering on both datasets\n",
    "    mbk_raw = MiniBatchKMeans(n_clusters=n_clusters, random_state=42)\n",
    "    mbk_norm = MiniBatchKMeans(n_clusters=n_clusters, random_state=42)\n",
    "    \n",
    "    clusters_raw = mbk_raw.fit_predict(X)\n",
    "    clusters_norm = mbk_norm.fit_predict(X_scaled)\n",
    "    \n",
    "    # 3. PCA Visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca_raw = pca.fit_transform(X)\n",
    "    X_pca_norm = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Plot PCA results\n",
    "    scatter_pca_raw = axes[0,0].scatter(X_pca_raw[:, 0], X_pca_raw[:, 1], \n",
    "                                      c=clusters_raw, cmap='tab10', alpha=0.6)\n",
    "    axes[0,0].set_title('PCA - Raw Data')\n",
    "    axes[0,0].set_xlabel('First Principal Component')\n",
    "    axes[0,0].set_ylabel('Second Principal Component')\n",
    "    plt.colorbar(scatter_pca_raw, ax=axes[0,0])\n",
    "    \n",
    "    scatter_pca_norm = axes[0,1].scatter(X_pca_norm[:, 0], X_pca_norm[:, 1], \n",
    "                                       c=clusters_norm, cmap='tab10', alpha=0.6)\n",
    "    axes[0,1].set_title('PCA - Normalized Data')\n",
    "    axes[0,1].set_xlabel('First Principal Component')\n",
    "    axes[0,1].set_ylabel('Second Principal Component')\n",
    "    plt.colorbar(scatter_pca_norm, ax=axes[0,1])\n",
    "    \n",
    "    # 4. t-SNE Visualization (on a sample if data is large)\n",
    "    sample_size = min(10000, len(X))\n",
    "    sample_idx = np.random.choice(len(X), sample_size, replace=False)\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    X_tsne_raw = tsne.fit_transform(X[sample_idx])\n",
    "    X_tsne_norm = tsne.fit_transform(X_scaled[sample_idx])\n",
    "    \n",
    "    # Plot t-SNE results\n",
    "    scatter_tsne_raw = axes[1,0].scatter(X_tsne_raw[:, 0], X_tsne_raw[:, 1], \n",
    "                                       c=clusters_raw[sample_idx], cmap='tab10', alpha=0.6)\n",
    "    axes[1,0].set_title('t-SNE - Raw Data (Sample)')\n",
    "    plt.colorbar(scatter_tsne_raw, ax=axes[1,0])\n",
    "    \n",
    "    scatter_tsne_norm = axes[1,1].scatter(X_tsne_norm[:, 0], X_tsne_norm[:, 1], \n",
    "                                        c=clusters_norm[sample_idx], cmap='tab10', alpha=0.6)\n",
    "    axes[1,1].set_title('t-SNE - Normalized Data (Sample)')\n",
    "    plt.colorbar(scatter_tsne_norm, ax=axes[1,1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Additional visualization: Cluster sizes\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    pd.Series(clusters_raw).value_counts().sort_index().plot(\n",
    "        kind='bar', ax=ax1, title='Cluster Sizes - Raw Data')\n",
    "    ax1.set_xlabel('Cluster')\n",
    "    ax1.set_ylabel('Number of Samples')\n",
    "    \n",
    "    pd.Series(clusters_norm).value_counts().sort_index().plot(\n",
    "        kind='bar', ax=ax2, title='Cluster Sizes - Normalized Data')\n",
    "    ax2.set_xlabel('Cluster')\n",
    "    ax2.set_ylabel('Number of Samples')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return clusters_raw, clusters_norm\n",
    "\n",
    "# Usage\n",
    "# Assuming df is your dataframe\n",
    "X = df.drop(['category', 'attack', 'is_benign'], axis=1, errors='ignore')\n",
    "clusters_raw, clusters_norm = visualize_clustering_comparison(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(X, y, n_clusters):\n",
    "    # Initialize clustering\n",
    "    mbk = MiniBatchKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        batch_size=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit and get clusters\n",
    "    clusters = mbk.fit_predict(X)\n",
    "    \n",
    "    # Internal validation (using X)\n",
    "    print(\"\\nInternal Validation Metrics:\")\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, clusters):.3f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(X, clusters):.3f}\")\n",
    "    print(f\"Davies-Bouldin Score: {davies_bouldin_score(X, clusters):.3f}\")\n",
    "    \n",
    "    # External validation (comparing with y)\n",
    "    print(\"\\nExternal Validation Metrics (compared to true labels):\")\n",
    "    print(f\"Adjusted Rand Index: {adjusted_rand_score(y, clusters):.3f}\")\n",
    "    print(f\"Normalized Mutual Information: {normalized_mutual_info_score(y, clusters):.3f}\")\n",
    "    \n",
    "    # Visualization using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Plot 1: Clusters\n",
    "    scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.6)\n",
    "    ax1.set_title('Clustering Results')\n",
    "    ax1.set_xlabel('First Principal Component')\n",
    "    ax1.set_ylabel('Second Principal Component')\n",
    "    plt.colorbar(scatter1, ax=ax1, label='Cluster Labels')\n",
    "    \n",
    "    # Plot 2: True Labels\n",
    "    scatter2 = ax2.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', alpha=0.6)\n",
    "    ax2.set_title('True Labels')\n",
    "    ax2.set_xlabel('First Principal Component')\n",
    "    ax2.set_ylabel('Second Principal Component')\n",
    "    plt.colorbar(scatter2, ax=ax2, label='True Labels')\n",
    "    \n",
    "    # Add a third plot for cluster sizes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cluster_sizes = pd.Series(clusters).value_counts().sort_index()\n",
    "    cluster_sizes.plot(kind='bar')\n",
    "    plt.title('Cluster Sizes')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return clusters, mbk\n",
    "\n",
    "# Preprocess data\n",
    "def prepare_data(df):\n",
    "    # Remove target columns for clustering\n",
    "    X = df.drop(['category', 'attack', 'is_benign'], axis=1)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled\n",
    "\n",
    "# Main clustering process\n",
    "def multi_level_clustering(df):\n",
    "    X_scaled = prepare_data(df)\n",
    "    \n",
    "    # 1. Binary clustering (is_benign)\n",
    "    print(\"\\nClustering for Binary Classification:\")\n",
    "    clusters_binary, model_binary = perform_clustering(X_scaled, df['is_benign'], n_clusters=2)\n",
    "    \n",
    "    # 2. Main categories clustering\n",
    "    print(\"\\nClustering for Main Categories:\")\n",
    "    clusters_main, model_main = perform_clustering(X_scaled, df['category'], n_clusters=6)\n",
    "    \n",
    "    # 3. Detailed attack types clustering\n",
    "    print(\"\\nClustering for Attack Types:\")\n",
    "    clusters_attack, model_attack = perform_clustering(X_scaled, df['attack'], n_clusters=19)\n",
    "    \n",
    "    # Add results to original dataframe\n",
    "    results_df = df.copy()\n",
    "    results_df['binary_cluster'] = clusters_binary\n",
    "    results_df['main_category_cluster'] = clusters_main\n",
    "    results_df['attack_type_cluster'] = clusters_attack\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Usage\n",
    "# Assuming df is your dataframe\n",
    "clustered_df = multi_level_clustering(df)\n",
    "\n",
    "# Analyze results\n",
    "def analyze_cluster_distribution(df):\n",
    "    print(\"\\nBinary Clustering Distribution:\")\n",
    "    print(pd.crosstab(df['binary_cluster'], df['is_benign']))\n",
    "    \n",
    "    print(\"\\nMain Categories Clustering Distribution:\")\n",
    "    print(pd.crosstab(df['main_category_cluster'], df['category']))\n",
    "    \n",
    "    print(\"\\nAttack Types Clustering Distribution:\")\n",
    "    print(pd.crosstab(df['attack_type_cluster'], df['attack']))\n",
    "\n",
    "# Analyze results\n",
    "analyze_cluster_distribution(clustered_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
