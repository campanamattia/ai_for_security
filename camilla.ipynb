{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Internet of Medical Things (IoMT) has become increasingly vital in healthcare, enabling continuous patient monitoring and automated medical services. However, this connectivity capabilities also introduce cybersecurity risks that could compromise patient care and privacy. The CICIoMT2024 dataset, developed by the Canadian Institute for Cybersecurity (CIC), provides a comprehensive benchmark for evaluating IoMT security solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rate e header lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RATE**: all in all, across all features Variance and IAT are strong indicators to differentiate attacks from benign traffic, especially DoS, DDoS and MQTT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY CLASSIFICATION-BALANCED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY-LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we implemented a LogisticRegression model to classify attacks and benign data. Optimising regularization parameter C (inverse of regularization strength), using GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY - RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we implemented an emsemble learning method for binary classification, Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing the number of trees to use in the ensemble\n",
    "\n",
    "In a Random Forest, each tree is trained on a subset of the training data selected by bootstrap sampling. The \"out-of-bag\" (OOB) data is the portion of the training data that was not selected during the bootstrap sampling. The OOB error is a measure of the model predictive performance.\n",
    "\n",
    "Observing the OOB estimation variation with the number of trees helps understanding after how many trees the model stabilizes, thus what's the optimal number of trees to train our RandomForest on. The point where the OOB error stops improving/fluctuating significantly indicates that the model generalizes well to unseen data, and adding more trees does not meaningfully improve the model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the aim is to confirm the results obtained using the Random Forest adopting another ensemble method. The following code processes data for binary classification with XGBoost algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALIBRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibration plot shown below compares the probabilities predicted by the Logistic Regression and the Random Forest with the real observed frequency of positive values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to observe the opposite behavior of the two classifiers. The blue line of Logistic Regression is closer to the one representing the perfect calibration (where the predicted probability exactly matches the observed probability) for low probability values, conversely for the Random Forest represented by the orange line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-AUC CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting ROC curve helps us understand sensibility and specificity of the two models, representing the ratio between true positive rate and false positives rate (false alarms). The distribution of both is excellent, but the Random Forest performs better, as suggested by the area under the curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following sections is to evaluate the classification metrics of the two models, in order to compare them on the validation and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALIDATION \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI-CLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a necessary step to prepare the dataset for a multiclass classification task, converting non-numerical labels and dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As concerns multi-class classification problems as the one considered, supposedly linear models are not able to capture the complexity of structures and relationships within data. The following code implements a Logistic Regression model to verify this assumption. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOMFOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non linear models are more advisable, in this section a Random Forest is implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what we did in the binary classification, in this section we are going to run an XGBoost model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DA SOTTOLINEARE COME MAI USIAMO TRE DATASET E IN PARTICOLARE QUELLO SENZA LA SELEZIONE DI FEATURES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsupervised learning \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
