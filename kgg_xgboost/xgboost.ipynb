{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from rich import print\n",
    "from rich.panel import Panel\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Create copy to avoid modifying original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Split features and target\n",
    "    X = df.drop(['is_benign', 'attack', 'category'], axis=1)\n",
    "    y = df['is_benign']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Print simplified but comprehensive model evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    model_name : str, optional\n",
    "        Name of the model for display purposes\n",
    "    \"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    # Calculate core metrics\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    # Create metrics table\n",
    "    table = Table(show_header=True, header_style=\"bold white\", box=None)\n",
    "    table.add_column(\"Metric\", style=\"cyan\")\n",
    "    table.add_column(\"Score\", justify=\"right\")\n",
    "    \n",
    "    # Add metrics rows with color coding\n",
    "    for metric, value in metrics.items():\n",
    "        color = \"green\" if value > 0.8 else \"yellow\" if value > 0.6 else \"red\"\n",
    "        table.add_row(\n",
    "            metric,\n",
    "            f\"[{color}]{value:.5f}[/{color}]\"\n",
    "        )\n",
    "    \n",
    "    # Calculate confusion matrix summary\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create confusion matrix table\n",
    "    cm_table = Table(show_header=True, header_style=\"bold white\", box=None)\n",
    "    cm_table.add_column(\"Guess \\\\ OG\", style=\"cyan\")\n",
    "    for i in range(cm.shape[1]):\n",
    "        cm_table.add_column(f\"Class {i}\", justify=\"right\")\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        row = [f\"Class {i}\"] + [str(cm[i, j]) for j in range(cm.shape[1])]\n",
    "        cm_table.add_row(*row)\n",
    "    \n",
    "    # Create a combined panel with two columns\n",
    "    combined_table = Table.grid(expand=True)\n",
    "    combined_table.add_column(justify=\"center\", ratio=1)\n",
    "    combined_table.add_column(justify=\"center\", ratio=1)\n",
    "    \n",
    "    combined_table.add_row(table, cm_table)\n",
    "    \n",
    "    # Create and display panel\n",
    "    panel = Panel(\n",
    "        combined_table,\n",
    "        title=f\"[bold]{model_name} - Performance Metrics and Confusion Matrix[/bold]\",\n",
    "        border_style=\"white\"\n",
    "    )\n",
    "    \n",
    "    console.print(\"\\n\", panel, \"\\n\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initial XGBoost model with balanced class weights\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1\n",
    "    )\n",
    "    \n",
    "    # Define parameter grid for optimization\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(y_test, y_pred, \"XGBoost\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file\n",
    "df = pd.read_csv('/kaggle/input/dataset/train_binary.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "X, y = preprocess_data(df)\n",
    "\n",
    "# Train and evaluate the model\n",
    "best_model= train_xgboost(X, y)\n",
    "best_model.save_model('xgboost_network_traffic_model.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
